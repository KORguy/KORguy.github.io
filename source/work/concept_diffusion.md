---
title: Semantic Guidance Tuning for Text-To-Image Diffusion Models
---

> üë¨ **Team**: Hyun Kang, Dohae Lee, Myungjin Shin, In-Kwon Lee
> üë®üèª‚Äçüíª **Role**: Primary Author 
> üìÖ **Date**: Dec 2023

<div class="text-center mb-4">
  <img src="/images/concept_diffusion_teaser.jpeg" alt="adisaktijrs" width="600" />
</div>

### Abstract
Recent advancements in text-to-image diffusion models have demonstrated impressive success in generating high-quality images with zero-shot general- ization capabilities. Yet, current models struggle to closely adhere to prompt semantics, often misrepresenting or overlooking specific attributes. To address this, we propose an approach that modulates the guidance of diffusion models during inference, requiring no training or optimization. Specifically, we first decompose the semantics in the guidance into a set of arbitrary concepts and monitor the guidance trajectory in relation to each concept. Our key observa- tion is that deviations in the model‚Äôs adherence to prompt semantics are highly correlated with the guidance‚Äôs divergence from one or more of these concepts. This highlights that semantic misalignment between the generated image and the prompt can be determined on-the-fly. Based on this observation, we devise a technique to steer the guidance direction towards any concept from which the model diverges. Extensive experimentation validates that our method improves the semantic alignment of images generated by diffusion models in response to prompts.

### ConceptDiffusion

<div class="text-center mb-4">
  <img src="/images/concept1.jpg" alt="adisaktijrs" width="600" />
</div>

We observe that semantic misalignment between the given prompt and the generated image is highly correlated to the divergence of the noise estimate from one or more concepts that are critical for successful synthesis.

<div class="text-center mb-4">
  <img src="/images/concept2.jpg" alt="adisaktijrs" width="600" />
</div>

Given a prompt e.g., ‚Äúa book and a chair", we extract the subject concepts {‚Äúa book‚Äù, ‚Äúa chair‚Äù} and compute their corresponding scores. The score for abstract concept is indirectly obtained. The Concept Guidance is then applied based on the cosine similarity between the prompt score and score for each concept.

##### Results
<div class="text-center mb-4">
  <img src="/images/cc.jpg" alt="adisaktijrs" width="600" />
</div>

üìù Paper: <a href="https://arxiv.org/abs/2312.15964v1" target="_blank">Semantic Guidance Tuning for Text-To-Image Diffusion Models
</a>